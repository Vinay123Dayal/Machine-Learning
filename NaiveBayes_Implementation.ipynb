{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2018117_HW1_CODE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3YCp9UeKPQN"
      },
      "source": [
        "IMPORTING LIBRARIES AND DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOJMzFN_IXXe"
      },
      "source": [
        " import pandas as pd\n",
        "import numpy as np\n",
        "from math import sqrt, pi\n",
        "import math\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "wine = load_wine()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfRF-VMEKXan"
      },
      "source": [
        "Splitting Test AND Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2iIxEmUo288",
        "outputId": "a2fc5f04-a83a-4660-8ff3-3c18c019d9e8"
      },
      "source": [
        "from sklearn import model_selection\n",
        "X_train, X_test, Y_train, Y_test=model_selection.train_test_split(wine.data, wine.target, test_size=0.30, random_state=50)\n",
        "listcount=[0]*3;\n",
        "for value in Y_train:\n",
        "  listcount[value]+=1;\n",
        "print(listcount[0],\" \",listcount[1], \" \",listcount[2]);\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43   48   33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qye1cBZKckJ"
      },
      "source": [
        "Separating classes to get all the features for which label 1,2,3 are present"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqyLmn8zPMH2"
      },
      "source": [
        "separateclass={}\n",
        "for i in range(len(X_train)):\n",
        "  if(Y_train[i] not in separateclass.keys()):\n",
        "    separateclass[Y_train[i]]=[];\n",
        "  separateclass[Y_train[i]].append(X_train[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J61rZDHjKm4P"
      },
      "source": [
        "Finding Standard Deviation and Mean for different Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnclXtiEss9x"
      },
      "source": [
        "\n",
        "\n",
        "## finding standard deviation and mean of different classes;\n",
        "\n",
        "ms_values={}\n",
        "for i in separateclass.keys():\n",
        "  mat=separateclass[i];\n",
        "  m1=np.mean(mat, axis=0);\n",
        "  s1=np.std(mat, axis=0);\n",
        "  ms_values[i]=[m1, s1];\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dUTa5D-KsTt"
      },
      "source": [
        "Calculating Probability function and Making calculator which predicts label for particular set of input. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkR_RbyEufDT"
      },
      "source": [
        "def calculate_prob(x, mean, std):\n",
        "  exponent = math.exp(-((x-mean)**2 / (2 * std**2 )))\n",
        "  m=(1/(math.sqrt(2*math.pi)*std))*exponent\n",
        "  return m;\n",
        "\n",
        "def calculator(testdata, listcount, ms_values, trainlength):\n",
        "  probdic={};\n",
        "  for i in ms_values.keys():\n",
        "    prob=listcount[i]/trainlength;\n",
        "    for j in range(len(testdata)):\n",
        "      prob=prob*calculate_prob(testdata[j],ms_values[i][0][j], ms_values[i][1][j]);\n",
        "    probdic[i]=prob;\n",
        "  first=max(probdic[0], probdic[1], probdic[2]);\n",
        "  if(first==probdic[0]):\n",
        "    return 0;\n",
        "  elif(first==probdic[1]):\n",
        "    return 1;\n",
        "  else:\n",
        "    return 2;\n",
        "\n",
        "m=calculator(X_test[0], listcount, ms_values, len(X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J663DfpOG9z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpZ7_ocVK5k8"
      },
      "source": [
        "Making Prediction from Test set to get Y_PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0otHCHuo0R4f"
      },
      "source": [
        "def prediction(xtest):\n",
        "  l1=[];\n",
        "  for i in xtest:\n",
        "    p=calculator(i,listcount,ms_values,len(X_train));\n",
        "    l1.append(p);\n",
        "  return l1;\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cihhr-jZLM4N"
      },
      "source": [
        "Making Metrics for evaluation of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOYW3ux0LKtH"
      },
      "source": [
        "ypred= prediction(X_test);\n",
        "\n",
        "def accuracy(ypred, ytest):\n",
        "  count=0;\n",
        "  for i in range(len(ytest)):\n",
        "    if(ypred[i]==ytest[i]):\n",
        "      count+=1\n",
        "  return count/len(ytest);\n",
        "\n",
        "def getconfusionmatrix(ytest, ypred1, numberoflabel):\n",
        "  matrix=[];\n",
        "  for i in range(numberoflabel):\n",
        "    l1=[];\n",
        "    for j in range(numberoflabel):\n",
        "      l1.append(0);\n",
        "    matrix.append(l1);\n",
        "  for i in range(len(ytest)):\n",
        "    if(ytest[i]==ypred1[i]):\n",
        "      matrix[ytest[i]][ytest[i]]+=1;\n",
        "    else:\n",
        "      matrix[ytest[i]][ypred1[i]]+=1;\n",
        "  return matrix;\n",
        "\n",
        "  \n",
        "def precision(confusion_matrix, index):\n",
        "  truepositives=0;\n",
        "  falsepositives=0;\n",
        "  for i in range(len(confusion_matrix)):\n",
        "    if(i==index):\n",
        "      truepositives+=confusion_matrix[index][index];\n",
        "    else:\n",
        "      falsepositives+=confusion_matrix[i][index];\n",
        "  return truepositives/(truepositives+falsepositives);\n",
        "\n",
        "def recall(confusion_matrix, index):\n",
        "  truepositives1=0;\n",
        "  falsenegatives=0;\n",
        "  for i in range(len(confusion_matrix)):\n",
        "    if(i==index):\n",
        "      truepositives1+=confusion_matrix[index][index];\n",
        "    else:\n",
        "      falsenegatives+=confusion_matrix[index][i];\n",
        "  return truepositives1/(truepositives1+falsenegatives);\n",
        "def f1score(confusion_matrix, index):\n",
        "  p=precision(confusion_matrix, index);\n",
        "  r=recall(confusion_matrix, index);\n",
        "  f1=2*(p*r)/(p+r)\n",
        "  print(\"for \",index,\" Precision: \",p,\"Recall: \",r, \"F1 Score: \",f1);\n",
        "  return f1;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjd6yGqZLYVK"
      },
      "source": [
        "Comparing Both models with Accuracy, F1-Score, Precision, Recall, Confusion metrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgVcVoj6Lg26",
        "outputId": "4b745e54-0a41-4021-8b15-f49673a10ec9"
      },
      "source": [
        "acc=accuracy(ypred, Y_test);\n",
        "print(\"accuracy: \",acc);\n",
        "\n",
        "confusion_matrix=getconfusionmatrix(Y_test, ypred,3);\n",
        "print(\"Confusion matrix: \",confusion_matrix)\n",
        "f1score(confusion_matrix, 0);\n",
        "f1score(confusion_matrix, 1);\n",
        "f1score(confusion_matrix, 2);\n",
        "\n",
        "\n",
        "##Implementing Naive Bayes\n",
        "classifier=GaussianNB()\n",
        "classifier.fit(X_train,Y_train);\n",
        "ypred2=classifier.predict(X_test);\n",
        "confusion_matrix2=getconfusionmatrix(Y_test, ypred2, 3);\n",
        "accuracy2=accuracy(ypred2, Y_test)\n",
        "print(\"Accuracy for In-built Gaussian NB: \",accuracy2);\n",
        "print(\"Confusion matrix for In-built Gaussian NB: \",confusion_matrix2);\n",
        "f1score(confusion_matrix2, 0);\n",
        "f1score(confusion_matrix2, 1);\n",
        "f1score(confusion_matrix2, 2);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  0.9814814814814815\n",
            "Confusion matrix:  [[15, 1, 0], [0, 23, 0], [0, 0, 15]]\n",
            "for  0  Precision:  1.0 Recall:  0.9375 F1 Score:  0.967741935483871\n",
            "for  1  Precision:  0.9583333333333334 Recall:  1.0 F1 Score:  0.9787234042553191\n",
            "for  2  Precision:  1.0 Recall:  1.0 F1 Score:  1.0\n",
            "Accuracy for In-built Gaussian NB:  0.9814814814814815\n",
            "Confusion matrix for In-built Gaussian NB:  [[15, 1, 0], [0, 23, 0], [0, 0, 15]]\n",
            "for  0  Precision:  1.0 Recall:  0.9375 F1 Score:  0.967741935483871\n",
            "for  1  Precision:  0.9583333333333334 Recall:  1.0 F1 Score:  0.9787234042553191\n",
            "for  2  Precision:  1.0 Recall:  1.0 F1 Score:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}